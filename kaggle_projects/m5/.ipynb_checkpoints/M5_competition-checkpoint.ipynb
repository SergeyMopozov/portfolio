{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle M5 competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "lib_path = '../../../frameworks/time_series_signals_sound'\n",
    "sys.path.append(lib_path)\n",
    "lib_path_2 = '../../../frameworks/'\n",
    "sys.path.append(lib_path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling import ts_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../../data/kaggle/M5/sales_train_evaluation.csv',\n",
       " '../../../data/kaggle/M5/sell_prices.csv',\n",
       " '../../../data/kaggle/M5/calendar.csv',\n",
       " '../../../data/kaggle/M5/sales_train_validation.csv',\n",
       " '../../../data/kaggle/M5/sample_submission.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('../../../data/kaggle/M5/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = pd.read_csv('../../../data/kaggle/M5/calendar.csv')\n",
    "#sales = pd.read_csv('../../../data/kaggle/M5/sales_train_evaluation.csv')\n",
    "#prices = pd.read_csv('../../../data/kaggle/M5/sell_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1969 entries, 0 to 1968\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   date          1969 non-null   object\n",
      " 1   wm_yr_wk      1969 non-null   int64 \n",
      " 2   weekday       1969 non-null   object\n",
      " 3   wday          1969 non-null   int64 \n",
      " 4   month         1969 non-null   int64 \n",
      " 5   year          1969 non-null   int64 \n",
      " 6   d             1969 non-null   object\n",
      " 7   event_name_1  162 non-null    object\n",
      " 8   event_type_1  162 non-null    object\n",
      " 9   event_name_2  5 non-null      object\n",
      " 10  event_type_2  5 non-null      object\n",
      " 11  snap_CA       1969 non-null   int64 \n",
      " 12  snap_TX       1969 non-null   int64 \n",
      " 13  snap_WI       1969 non-null   int64 \n",
      "dtypes: int64(7), object(7)\n",
      "memory usage: 215.5+ KB\n"
     ]
    }
   ],
   "source": [
    "calendar.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>d</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  wm_yr_wk    weekday  wday  month  year    d event_name_1  \\\n",
       "0  2011-01-29     11101   Saturday     1      1  2011  d_1          NaN   \n",
       "1  2011-01-30     11101     Sunday     2      1  2011  d_2          NaN   \n",
       "2  2011-01-31     11101     Monday     3      1  2011  d_3          NaN   \n",
       "3  2011-02-01     11101    Tuesday     4      2  2011  d_4          NaN   \n",
       "4  2011-02-02     11101  Wednesday     5      2  2011  d_5          NaN   \n",
       "\n",
       "  event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \n",
       "0          NaN          NaN          NaN        0        0        0  \n",
       "1          NaN          NaN          NaN        0        0        0  \n",
       "2          NaN          NaN          NaN        0        0        0  \n",
       "3          NaN          NaN          NaN        1        1        0  \n",
       "4          NaN          NaN          NaN        1        0        1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30490 entries, 0 to 30489\n",
      "Columns: 1947 entries, id to d_1941\n",
      "dtypes: int64(1941), object(6)\n",
      "memory usage: 452.9+ MB\n"
     ]
    }
   ],
   "source": [
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6841121 entries, 0 to 6841120\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   store_id    object \n",
      " 1   item_id     object \n",
      " 2   wm_yr_wk    int64  \n",
      " 3   sell_price  float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 208.8+ MB\n"
     ]
    }
   ],
   "source": [
    "prices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast(df):\n",
    "    cols = df.dtypes.index.tolist()\n",
    "    types = df.dtypes.values.tolist()\n",
    "    for i,t in enumerate(types):\n",
    "        if 'int' in str(t):\n",
    "            if df[cols[i]].min() > np.iinfo(np.int8).min and df[cols[i]].max() < np.iinfo(np.int8).max:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.int8)\n",
    "            elif df[cols[i]].min() > np.iinfo(np.int16).min and df[cols[i]].max() < np.iinfo(np.int16).max:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.int16)\n",
    "            elif df[cols[i]].min() > np.iinfo(np.int32).min and df[cols[i]].max() < np.iinfo(np.int32).max:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.int32)\n",
    "            else:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.int64)\n",
    "        elif 'float' in str(t):\n",
    "            if df[cols[i]].min() > np.finfo(np.float16).min and df[cols[i]].max() < np.finfo(np.float16).max:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.float16)\n",
    "            elif df[cols[i]].min() > np.finfo(np.float32).min and df[cols[i]].max() < np.finfo(np.float32).max:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.float32)\n",
    "            else:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.float64)\n",
    "        elif t == np.object:\n",
    "            if cols[i] == 'date':\n",
    "                df[cols[i]] = pd.to_datetime(df[cols[i]], format='%Y-%m-%d')\n",
    "            else:\n",
    "                df[cols[i]] = df[cols[i]].astype('category')\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = downcast(sales)\n",
    "prices = downcast(prices)\n",
    "calendar = downcast(calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1969 entries, 0 to 1968\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   date          1969 non-null   datetime64[ns]\n",
      " 1   wm_yr_wk      1969 non-null   int16         \n",
      " 2   weekday       1969 non-null   category      \n",
      " 3   wday          1969 non-null   int8          \n",
      " 4   month         1969 non-null   int8          \n",
      " 5   year          1969 non-null   int16         \n",
      " 6   d             1969 non-null   category      \n",
      " 7   event_name_1  162 non-null    category      \n",
      " 8   event_type_1  162 non-null    category      \n",
      " 9   event_name_2  5 non-null      category      \n",
      " 10  event_type_2  5 non-null      category      \n",
      " 11  snap_CA       1969 non-null   int8          \n",
      " 12  snap_TX       1969 non-null   int8          \n",
      " 13  snap_WI       1969 non-null   int8          \n",
      "dtypes: category(6), datetime64[ns](1), int16(2), int8(5)\n",
      "memory usage: 144.0 KB\n"
     ]
    }
   ],
   "source": [
    "calendar.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30490 entries, 0 to 30489\n",
      "Columns: 1947 entries, id to d_1941\n",
      "dtypes: category(6), int16(1317), int8(624)\n",
      "memory usage: 96.6 MB\n"
     ]
    }
   ],
   "source": [
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6841121 entries, 0 to 6841120\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Dtype   \n",
      "---  ------      -----   \n",
      " 0   store_id    category\n",
      " 1   item_id     category\n",
      " 2   wm_yr_wk    int16   \n",
      " 3   sell_price  float16 \n",
      "dtypes: category(2), float16(1), int16(1)\n",
      "memory usage: 45.8 MB\n"
     ]
    }
   ],
   "source": [
    "prices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 715 ms, total: 1min 3s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sales_valid = pd.read_csv('../../../data/kaggle/M5/sales_train_validation.csv')\n",
    "sample = pd.read_csv('../../../data/kaggle/M5/sample_submission.csv', index_col=0)\n",
    "valid = []\n",
    "for idx, row in sales_valid.iterrows():\n",
    "    valid.append(ts_models.baseline_forecast(row[6:], \n",
    "                                       ftype='season mean', \n",
    "                                       steps=28, \n",
    "                                       n_seasons=4, \n",
    "                                       time_index=False,\n",
    "                                       index=sample.columns).to_frame().T)\n",
    "\n",
    "valid = pd.concat(valid).reset_index(drop=True)\n",
    "valid['id'] = data_valid['id']\n",
    "    \n",
    "    \n",
    "evalut = []\n",
    "for idx, row in sales.iterrows():\n",
    "    evalut.append(ts_models.baseline_forecast(row[6:], \n",
    "                                       ftype='season mean', \n",
    "                                       steps=28, \n",
    "                                       n_seasons=4, \n",
    "                                       time_index=False,\n",
    "                                       index=sample.columns).to_frame().T)\n",
    "\n",
    "evalut = pd.concat(evalut).reset_index(drop=True)\n",
    "evalut['id'] = data['id']\n",
    "    \n",
    "submission =  pd.concat([valid, evalut]).set_index('id')\n",
    "submission.to_csv('baselin_sub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 13s, sys: 30.7 s, total: 1min 44s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# melt series and merge all data\n",
    "df = pd.melt(sales, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name='d', value_name='sold').dropna()\n",
    "df = pd.merge(df, calendar, on='d', how='left')\n",
    "df = pd.merge(df, prices, on=['store_id','item_id','wm_yr_wk'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del sales, prices, calendar\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59181090 entries, 0 to 59181089\n",
      "Data columns (total 22 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   id            category      \n",
      " 1   item_id       category      \n",
      " 2   dept_id       category      \n",
      " 3   cat_id        category      \n",
      " 4   store_id      category      \n",
      " 5   state_id      category      \n",
      " 6   d             object        \n",
      " 7   sold          int16         \n",
      " 8   date          datetime64[ns]\n",
      " 9   wm_yr_wk      int16         \n",
      " 10  weekday       category      \n",
      " 11  wday          int8          \n",
      " 12  month         int8          \n",
      " 13  year          int16         \n",
      " 14  event_name_1  category      \n",
      " 15  event_type_1  category      \n",
      " 16  event_name_2  category      \n",
      " 17  event_type_2  category      \n",
      " 18  snap_CA       int8          \n",
      " 19  snap_TX       int8          \n",
      " 20  snap_WI       int8          \n",
      " 21  sell_price    float16       \n",
      "dtypes: category(11), datetime64[ns](1), float16(1), int16(3), int8(5), object(1)\n",
      "memory usage: 2.8+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dict \n",
    "d_id = dict(zip(df.id.cat.codes, df.id))\n",
    "d_store_id = dict(zip(df.store_id.cat.codes, df.store_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event coumns preprocessing\n",
    "list1=['event_name_1','event_type_1','event_name_2','event_type_2']\n",
    "for i in list1:\n",
    "    \n",
    "    df[i] = df[i].cat.add_categories(\"nan\").fillna(\"nan\")\n",
    "    df[i]=LabelEncoder().fit_transform(df[i]).astype(np.int8)\n",
    "    df[i]=df[i].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract days\n",
    "df.d = df['d'].apply(lambda x: x.split('_')[1]).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.dtypes.index.tolist()\n",
    "types = df.dtypes.values.tolist()\n",
    "for i,type in enumerate(types):\n",
    "    if type.name == 'category':\n",
    "        df[cols[i]] = df[cols[i]].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df['date'].apply(lambda x: x.strftime('%d')).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59181090 entries, 0 to 59181089\n",
      "Data columns (total 22 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   id            int16  \n",
      " 1   item_id       int16  \n",
      " 2   dept_id       int8   \n",
      " 3   cat_id        int8   \n",
      " 4   store_id      int8   \n",
      " 5   state_id      int8   \n",
      " 6   d             int16  \n",
      " 7   sold          int16  \n",
      " 8   date          int8   \n",
      " 9   wm_yr_wk      int16  \n",
      " 10  weekday       int8   \n",
      " 11  wday          int8   \n",
      " 12  month         int8   \n",
      " 13  year          int16  \n",
      " 14  event_name_1  int8   \n",
      " 15  event_type_1  int8   \n",
      " 16  event_name_2  int8   \n",
      " 17  event_type_2  int8   \n",
      " 18  snap_CA       int8   \n",
      " 19  snap_TX       int8   \n",
      " 20  snap_WI       int8   \n",
      " 21  sell_price    float16\n",
      "dtypes: float16(1), int16(6), int8(15)\n",
      "memory usage: 2.0 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lags sold\n",
    "lags = [28,35,42,49]\n",
    "for lag in lags:\n",
    "    df['sold_lag_'+str(lag)] = df.groupby(['id', \n",
    "                                           'item_id', \n",
    "                                           'dept_id',\n",
    "                                           'cat_id', \n",
    "                                           'store_id', \n",
    "                                           'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lags event\n",
    "lags2 = [1,2]\n",
    "for lag in lags2:\n",
    "    df['event1_lag_'+str(lag)] = df.groupby(['id', \n",
    "                                             'item_id', \n",
    "                                             'dept_id', \n",
    "                                             'cat_id', \n",
    "                                             'store_id', \n",
    "                                             'state_id'],as_index=False)['event_name_1']\\\n",
    "                                    .shift(lag)\\\n",
    "                                    .astype(np.float16)\n",
    "    \n",
    "    df['event1_lag_'+str(lag)].fillna(100, inplace=True)\n",
    "    df['event1_lag_'+str(lag)] = df['event1_lag_'+str(lag)].astype(np.int8)\n",
    "    df['event1_lag_'+str(lag)] = df['event1_lag_'+str(lag)].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean sold of item by all stores\n",
    "df['item_sold_avg'] = df.groupby('item_id')['sold'].transform('mean').astype(np.float16)    \n",
    "#df['state_sold_avg'] = df.groupby('state_id')['sold'].transform('mean').astype(np.float16)\n",
    "#df['store_sold_avg'] = df.groupby('store_id')['sold'].transform('mean').astype(np.float16)\n",
    "\n",
    "# mean sold  by category, department, cat + dep, store + item, cat + item, dep+item, store+cat+dep\n",
    "df['cat_sold_avg'] = df.groupby('cat_id')['sold'].transform('mean').astype(np.float16)\n",
    "df['dept_sold_avg'] = df.groupby('dept_id')['sold'].transform('mean').astype(np.float16)\n",
    "df['cat_dept_sold_avg'] = df.groupby(['cat_id','dept_id'])['sold'].transform('mean').astype(np.float16)\n",
    "df['store_item_sold_avg'] = df.groupby(['store_id','item_id'])['sold'].transform('mean').astype(np.float16)\n",
    "df['cat_item_sold_avg'] = df.groupby(['cat_id','item_id'])['sold'].transform('mean').astype(np.float16)\n",
    "df['dept_item_sold_avg'] = df.groupby(['dept_id','item_id'])['sold'].transform('mean').astype(np.float16)\n",
    "#df['state_store_sold_avg'] = df.groupby(['state_id','store_id'])['sold'].transform('mean').astype(np.float16)\n",
    "#df['state_store_cat_sold_avg'] = df.groupby(['state_id','store_id','cat_id'])['sold'].transform('mean').astype(np.float16)\n",
    "df['store_cat_dept_sold_avg'] = df.groupby(['store_id','cat_id','dept_id'])['sold'].transform('mean').astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace week number to atarted from zero  \n",
    "df['wm_yr_wk_linear']=LabelEncoder().fit_transform(df['wm_yr_wk'].values).astype(np.int16)\n",
    "df.drop(['wm_yr_wk'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add week price lag and diff\n",
    "df['price_lag'] = df.groupby(['id', \n",
    "                              'item_id', \n",
    "                              'dept_id', \n",
    "                              'cat_id', \n",
    "                              'store_id', \n",
    "                              'state_id'],as_index=False)['sell_price'].shift(7).astype(np.float16)\n",
    "# TODO sell price contain nan price-diff - too\n",
    "df['price-diff']=df['price_lag']-df['sell_price']\n",
    "df.drop(['price_lag'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add value of cents - 99 effect ?\n",
    "df['sell_price'].fillna(-1,inplace=True)\n",
    "df['decimal']=df['sell_price'].apply(lambda x: 100*(x-int(x))).astype(np.int16)\n",
    "df['sell_price'].replace(-1,np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate expanding mean price with window 2\n",
    "df['expanding_price_mean'] = df.groupby(['id', \n",
    "                                         'item_id', \n",
    "                                         'dept_id', \n",
    "                                         'cat_id', '\n",
    "                                         store_id', \n",
    "                                         'state_id'])['sell_price']\\\n",
    "                                .transform(lambda x: x.expanding(2).mean())\\\n",
    "                                .astype(np.float16)\n",
    "# calculate difference\n",
    "df['diff_moving_mean']=df['expanding_price_mean']-df['sell_price']\n",
    "\n",
    "# drop expanding mean\n",
    "df.drop(['expanding_price_mean'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ???\n",
    "df['price-diff']=df['price-diff'].astype(np.float16)\n",
    "# drop wdas - same as weekday\n",
    "df.drop(['wday'], axis=1, inplace=True)\n",
    "df['decimal']=df['decimal'].astype(np.int8)\n",
    "# encode year\n",
    "df['year']=LabelEncoder().fit_transform(df['year']).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?? sell price  not change - may be erros\n",
    "df['daily_avg_sold'] = df.groupby(['id', \n",
    "                                   'item_id', \n",
    "                                   'dept_id', \n",
    "                                   'cat_id', \n",
    "                                   'store_id', \n",
    "                                   'state_id','d'])['sell_price'].transform('mean').astype(np.float16)\n",
    "# mean price\n",
    "df['avg_sold'] = df.groupby(['id', \n",
    "                             'item_id', \n",
    "                             'dept_id', \n",
    "                             'cat_id', \n",
    "                             'store_id', \n",
    "                             'state_id'])['sell_price'].transform('mean').astype(np.float16)\n",
    "# difference between daily price and avg price (may be mean sells)\n",
    "df['selling_trend'] = (df['daily_avg_sold'] - df['avg_sold']).astype(np.float16)\n",
    "df.drop(['daily_avg_sold','avg_sold'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max price\n",
    "df['price_max'] = df.groupby(['store_id','item_id'])['sell_price'].transform('max')\n",
    "#df['price_min'] = df.groupby(['store_id','item_id'])['sell_price'].transform('min')\n",
    "#df['price_std'] = df.groupby(['store_id','item_id'])['sell_price'].transform('std')\n",
    "#df['price_mean'] = df.groupby(['store_id','item_id'])['sell_price'].transform('mean')\n",
    "\n",
    "# relate to max price\n",
    "df['price_norm'] = df['sell_price']/df['price_max']\n",
    "\n",
    "# relate price to mean by month and year\n",
    "#df['price_momentum'] = df['sell_price']/df.groupby(['store_id','item_id'])['sell_price'].transform(lambda x: x.shift(1))\n",
    "df['price_momentum_m'] = df['sell_price']/df.groupby(['store_id','item_id','month'])['sell_price'].transform('mean')\n",
    "df['price_momentum_y'] = df['sell_price']/df.groupby(['store_id','item_id','year'])['sell_price'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['rolling_sold_mean'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['sold'].transform(lambda x: x.rolling(window=7).mean()).astype(np.float16)\n",
    "#df['expanding_sold_mean'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['sold'].transform(lambda x: x.expanding(2).mean()).astype(np.float16)\n",
    "#df['daily_avg_sold'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id','d'])['sold'].transform('mean').astype(np.float16)\n",
    "#df['avg_sold'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['sold'].transform('mean').astype(np.float16)\n",
    "#df['selling_trend'] = (df['daily_avg_sold'] - df['avg_sold']).astype(np.float16)\n",
    "#df.drop(['daily_avg_sold','avg_sold'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop category\n",
    "list3=['cat_id','state_id']\n",
    "for i in list3:\n",
    "    df.drop([i], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preapare data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['d']>=49]\n",
    "df.to_pickle('data.pkl')\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data.pkl')\n",
    "valid_csv=data[(data['d']>=1914) & (data['d']<1942)][['id','d','sold']]\n",
    "test = data[data['d']>=1942][['id','d','sold']]\n",
    "eval_preds = test['sold']\n",
    "valid_preds_csv=valid_csv['sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_column=[]\n",
    "for i in data.columns:\n",
    "    if(str(data.dtypes[i])=='category'):\n",
    "        cat_column.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for store in d_store_id:\n",
    "    df = data[data['store_id']==store]\n",
    "    \n",
    "    X_train, y_train = df[df['d']<1914].drop('sold',axis=1), df[df['d']<1914]['sold']\n",
    "    X_valid_csv, y_valid_csv = df[(df['d']>=1914) & (df['d']<1942)].drop('sold',axis=1), df[(df['d']>=1914) & (df['d']<1942)]['sold']\n",
    "    X_test = df[df['d']>=1942].drop('sold',axis=1)\n",
    "    \n",
    "    model = LGBMRegressor(\n",
    "        learning_rate= 0.05,\n",
    "        subsample=0.6,\n",
    "        feature_fraction=0.6,\n",
    "        num_iterations = 1200,\n",
    "        max_bin=350,\n",
    "        num_leaves= 300,\n",
    "        lambda_l2=0.003,\n",
    "        max_depth=200,\n",
    "        min_data_in_leaf= 80,\n",
    "        force_row_wise= True,\n",
    "    )\n",
    "    print('*****Prediction for Store: {}*****'.format(d_store_id[store]))\n",
    "    model.fit(X_train, y_train, eval_set=[(X_train,y_train),(X_valid_csv,y_valid_csv)],\n",
    "             eval_metric='rmse',  verbose=100, early_stopping_rounds=20,categorical_feature=cat_column)\n",
    "    \n",
    "    valid_preds_csv[X_valid_csv.index] = model.predict(X_valid_csv)\n",
    "    eval_preds[X_test.index] = model.predict(X_test)\n",
    "    filename = 'model'+str(d_store_id[store])+'.pkl'\n",
    "\n",
    "    #保存模型\n",
    "    joblib.dump(model, filename)\n",
    "    del model, X_train, y_train, X_valid_csv, y_valid_csv\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_csv['sold'] = valid_preds_csv\n",
    "validation = valid_csv[['id','d','sold']]\n",
    "validation = pd.pivot(validation, index='id', columns='d', values='sold').reset_index()\n",
    "validation.columns=['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "validation.id = validation.id.map(d_id).str.replace('evaluation','validation')\n",
    "\n",
    "test['sold'] = eval_preds\n",
    "evaluation = test[['id','d','sold']]\n",
    "evaluation = pd.pivot(evaluation, index='id', columns='d', values='sold').reset_index()\n",
    "evaluation.columns=['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "evaluation.id = evaluation.id.map(d_id)\n",
    "\n",
    "#创建提交文件\n",
    "submit = pd.concat([validation,evaluation]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "for i in range(1,29):\n",
    "    submit['F'+str(i)] *= 1.04\n",
    "\n",
    "submit.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
