{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping car images\n",
    " \n",
    "As side effect of data scriping we got links on car images, so now we can download it and use inf CV tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import os\n",
    "import errno\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../data/1/source_data/source_frame_all_offer2020-01-22 12:37.pckl',\n",
       " '../../data/1/source_data/total_frame_valid_links_2020-01-23 11:07.pckl',\n",
       " '../../data/1/source_data/broken_index_df_2020-01-29 06:19.csv',\n",
       " '../../data/1/source_data/broken_index_df_2020-01-29 17:56.csv',\n",
       " '../../data/1/source_data/broken_index_df_2020-01-28 18:57.csv',\n",
       " '../../data/1/source_data/clean_data_offer_used 2020-09-04 13:17.csv',\n",
       " '../../data/1/source_data/clean_data_offer_used 2020-03-02 20:04.csv',\n",
       " '../../data/1/source_data/broken_index_df_2020-01-30 12:32.csv',\n",
       " '../../data/1/source_data/page_2020-01-22 09:48.csv',\n",
       " '../../data/1/source_data/broken_index_df_2020-01-30 13:21.csv',\n",
       " '../../data/1/source_data/region_data_ 2020-03-03 17:08.csv',\n",
       " '../../data/1/source_data/clean_data_offer_used 2020-03-03 17:14.csv',\n",
       " '../../data/1/source_data/clean_offer_frame_all2020-01-22 12:40.pckl',\n",
       " '../../data/1/source_data/region_data_ 2020-03-03 16:57.csv',\n",
       " '../../data/1/source_data/broken_index_df_2020-01-30 07:21.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('../../data/1/source_data/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "offer_data = pd.read_pickle('./source_data/clean_offer_frame_all2020-01-22 12:40.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check valid links\n",
    "def validate_links(img_links):\n",
    "    valid_links = []\n",
    "    for l in img_links:\n",
    "        if '_crpd' not in l:\n",
    "            l = 'https:' + l\n",
    "            valid_links.append(l)\n",
    "    return valid_links\n",
    "\n",
    "\n",
    "links_frame = offer_data[['img_links']].copy()\n",
    "\n",
    "links_frame['total_img_count'] = links_frame.img_links.apply(lambda row: len(row))\n",
    "links_frame['valid_img_links'] = links_frame.img_links.apply(lambda row: validate_links(row))\n",
    "links_frame['valid_img_count'] = links_frame.valid_img_links.apply(lambda row: len(row))\n",
    "\n",
    "total_frame = pd.concat([offer_data , links_frame], axis=1)\n",
    "total_frame.to_pickle('./source_data/total_frame_valid_links_' \\\n",
    "                      + datetime.today().strftime('%Y-%m-%d %H:%M') + '.pckl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566760"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total valid links\n",
    "total_link = total_frame['valid_img_count'].sum()\n",
    "total_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download img\n",
    "Web scrapping it's not stable process so some times we get broken images, but we can save broken links and iteratively download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list for index of cars which didn't download\n",
    "brocken_index = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 9s, sys: 11.8 s, total: 4min 21s\n",
      "Wall time: 31min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in links_frame[links_frame['valid_img_count'] != 0].index[232120:]:\n",
    "    dir_path = './img/'+str(i)+'/'\n",
    "    if not os.path.exists(os.path.dirname(dir_path)):\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(dir_path))\n",
    "        except OSError as exc: \n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise    \n",
    "    for j, link in enumerate(links_frame['valid_img_links'].iloc[i]):\n",
    "        try:\n",
    "            img = requests.get(link)\n",
    "            open(dir_path + str(j) + '.webp', 'wb').write(img.content)\n",
    "        except Exception as e:\n",
    "            print('Error!', link)\n",
    "            brocken_index.append(i)\n",
    "            print(e)\n",
    "            #time.sleep(600)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save broken index\n",
    "broken_index_df = pd.DataFrame(pd.Series(brocken_index).unique(), columns=['broken_index'])\n",
    "broken_index_df.to_csv('./source_data/broken_index_df_' + datetime.today().strftime('%Y-%m-%d %H:%M') + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# download broken img\n",
    "\n",
    "for i in broken_index_df.broken_index:\n",
    "    dir_path = './img/'+str(i)+'/'\n",
    "    print(dir_path)\n",
    "    if not os.path.exists(os.path.dirname(dir_path)):\n",
    "        try:\n",
    "            \n",
    "            os.makedirs(os.path.dirname(dir_path))\n",
    "        except OSError as exc: \n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise    \n",
    "    for j, link in enumerate(links_frame['valid_img_links'].iloc[i]):\n",
    "        try:\n",
    "            print(link)\n",
    "            img = requests.get(link)\n",
    "            open(dir_path + str(j) + '.webp', 'wb').write(img.content)\n",
    "        except Exception as e:\n",
    "            print('Error!', link)\n",
    "            brocken_index.append(i)\n",
    "            print(e)\n",
    "            #time.sleep(600)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566760\n",
      "566760\n",
      "CPU times: user 42.2 s, sys: 31.6 s, total: 1min 13s\n",
      "Wall time: 2h 56min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# check total downloading \n",
    "total_img = 0\n",
    "for path in glob.glob('./img/*'):\n",
    "    total_img += len(glob.glob(path +'/*.webp'))\n",
    "    #break\n",
    "print(total_link)\n",
    "print(total_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All images downloaded!\n",
    "Path structure for image datatatset is './img/< directory index >/< number of picture>.webp'\n",
    "\n",
    "\n",
    "## Tasks that can be decided with this dataset\n",
    "1. Classification - predict  producer, body type etc.\n",
    "2. Regression - predict milage, price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
